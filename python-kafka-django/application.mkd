Дата отправки: 2019-09-30 23:48

# Название доклада

Строим микросервисное приложение используя Kafka и Django


# Тезисы


Планирую рассказать о том, как Kafka может быть использована в микросервисном приложении в качестве "шины" передачи данных. Остановлюсь на том, зачем вообще может быть нужна Kafka в микросервисах и за пределами микросервисов. Покажу, как можно использовать Kafka для ускорения отдачи результата пользователю в системах, сделанных на синхронных питонячьих фреймворках (в основном на примере Django), а также расскажу, почему Kafka может быть полезна и в случае асинхронных фреймворков (aiohttp).


План выступления **(будет значительно меняться)**:
1. почему нам понадобилась Kafka в приложении:
  1) большой поток данных, который:
    1] нужно обрабатывать надёжно
    2] нужно обрабатывать оперативно
    3] может увеличиться вскоре и нужно быть к этому готовыми
  2) необходимость как-то общаться микросервисам между собой
  3) kafka уже достаточно устоявшийся продукт, который в т.ч. можно получить как «SaaS» (AWS MSK)
2. Краткое введение, что такое Kafka
  1) Основные "киты" Kafk'и:
    1] распределённость,
    2] масштабируемость,
    3] отказоустойчивость
  2) Основные "концепции":
    1] продьюсеры и консумеры
    2] топики и партиции
    3] брокеры Кафки и координаторы/менеджеры брокеров в лице Zookeeper
  3) Почему Кафка так быстра
3. Python библиотеки для работы с Kafka
  1) python-kafka
  2) pykafka
  3) aiokafka
  4) confluent-kafka
4. Каким способом мы используем Kafka
  1) Общий вид архитектуры проекта
    - "воркеры", собирающие внешние данные из HTTP (REST) / AMQP (Rabbit) источников в "промежуточные" топики Кафки в "сыром" виде
    - сервисы, обрабатывающие сырые данные из промежуточных топиков и перекладывающие обработанные, структурированные данные в основные топики
    - сервисы, "обогащающие" полученные данные дополнительной информацией на основе других внешних источников
    - "потоковое" (создание сущностей, обновление состояния) взаимодействие между остальными микросервисами также происходит через отдельные топики
  2) Схема данных: нужна ли? Если нужна, то:
    - В каком формате она должна быть? (JSON, Avro, ещё что-то?)
    - Где схема должна храниться? (Непосредственно в сообщении? Отдельный сервис схем?)
  3) Проблемы дальнейшего роста, масштабирования:
    - сколько топиков нам нужно для работы приложения?
    - сколько партишенов и консюмеров нам нужно, учитывая возможные накладные расходы при их увеличении
    - нужно ли держать отдельный "контрольный канал" для контроля гарантированной доставки сообщений



# На какую аудиторию рассчитан ваш доклад? (уровень, сфера деятельности) 

Уровень выше среднего. Сфера: веб, бекенд, микросервисы


# Комфортный для вас временной слот 

 60 мин (45 + 15 QA)


# Должность *

Lead Software Engineer

# Компания, ссылка на сайт *

http://bitnet.by

# Ссылки на ваши предыдущие выступления (видео / презентации) *

Список видео и презентаций здесь: https://shurph.github.io/talks/


# Страна. Город *

Республика Беларусь. Минск


# Ссылки на ваши профили в социальных сетях: Linkedin / Twitter / Facebook / GitHub / Stack Overflow *

Twitter: http://twitter.com/shurph 
GitHub: http://github.com/shurph
LinkedIn: https://www.linkedin.com/in/nikolay-saskovets/

# Необходима ли вам оплата проезда до места конференции? (решение об оплате трансфера принимается индивидуально)

Необходима


# Необходима ли вам оплата гостиницы? (решение об оплате проживания принимается индивидуально) *

Необходима


# Откуда вы узнали о конференции или кто Вас пригласил выступить?

Пригласил выступить Nikolay Karelin

# Комментарии / Пожелания / Предложения / Замечания / Вопросы

Про **Комфортный для вас временной слот**: так-то мне комфортнее формат «40 мин (30 + 10 QA)», но по опыту моего предыдущего выступления про Kafka есть ощущение, что понадобится все 45 минут, чтобы более-менее подробно/досконально раскрыть тему.


Про гостиницу/проезд: буду ещё раз уточнять у своей компании, но пока так (маловероятно, что ситуация изменится).
