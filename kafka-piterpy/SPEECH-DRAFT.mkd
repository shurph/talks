
1)
Добры день, меня зовут Николай Сасковец.
Вот уже несколько лет я соприкасаюсь с питоном, а последние чуть более чем пол года я занимался тем, что помогал команде питонистов перенести монолитное javascript-приложение на микросервисные рельсы, переписав, естественно, все на питоне. Или почти все.

И в центр нашего решения мы поместили Кафку.
Кстати! Поднимите пожалуйста руки, кто уже писал что-то с Кафкой, исползует ее в проектах.
А еще поднимите те, кто про Кафку хорошенько читал.

2)
И так, на руках у нас был монолит на javascript. Руковтворное чудо.
Всем хорош! Кроме того, что совершенно не держал нагрузку, код был несколько очень запутан и были некоторые вопросы по безопасности.
Настоящий MVP, одним словом.
Кстати, не часто мне доводилось видеть, чтобы бизнес отказывался от идеи выпустить MVP в продакшен и продолжать жить именно с ним.
От этого было еще интереснее!

Совсем чуть-чуть скажу про приложение.
Приложение занималось тем, что собирало из различных источников кучу данных о спортивных событиях, как-то их у себя аггрегировало и анализировало. А потом уже предоставляло пользователям различные сервисы, основываясь на этих данных.
И если в MVP было только пару видов спорта, то к продакшену хотели сразу все и в полном обьеме! Это сильно все меняло. Именно тогда в первый раз подумали о Кафке, которая вполне могла бы справиться с таким потоком данных.

3)
Но сначала давайте чуть-чуть про микросервисы.
Конечно, все мы прекрасно знаем, что микросервисы решают все наши проблемы!

4)
Но действительно ли это так?
Вот у нас был монолит. Мы разбросали его куски по облачкам микросервисов и наладили связи между ними. Общаются у нас микросервисы, допустим, через REST API. Или с помощью GraphQL...
Про что-то такое вам рассказывали на предыдущем докладе...
Или расскажут на следующем.

5)
А наше приложение начало расти, микросервисов стало больше.

6)
Связей между сервисами начинает становиться больше

7)
И еще больше!
Пока у нас не начинает возникать мысль, что каждый сервис общается с каждым другим сервисом, и может быть не по одному разу. Но это не точно.

8)
И так, у нас рано или поздно может возникнуть понимание, что сервисы-то у нас черезчур друг от друго зависимы, высокая связность у нас в нашей микросервисной архитектуре...

9)
А микросервисное ли у нас вообще приложение, или какой-то, простите, распределенный монолит?!
Ну... это все конечно слова... теория!

10)
Давайте рассмотрим практический случай.
Вот у нас запро от пользователя. Он затрагивает три микросервиса.
А, напомню, в название моего доклада есть слово Django. Поэтому все у нас идет синхронно, последовательно,... павольна! не быстро, то есть.

11)
А еще у нас-то может оказаться, напомню, распределенный монолит.
И запрос от пользователя может пройтись по нашим микросервисам 5, 6, 7 раз!
И пользователь будет ждать.
А не хотелось бы.

К счастью, в нашем случае, удача была на нашей стороне и все вот эти опросы других четырех сервисов никак не влияли на конечный результат для пользователя. Они лишь запускали какие-то изменения в системе, нужные самой системе, а не пользователю вот прямо сейчас.

12)
Ну и конечно же, первое что приходит на ум питонисту, когда у него на руках джанго и намечается какое-то асинхронное поведение.
Celery!
Вынесем те участки кода, которые взаимодействуют с другими микросервисами, в Celery таски! Делов-то!

Однако, здесь возникают моментики...
Ранее при каких-то проблемах в цепочке запросов мы могли просто сказать пользователю «Моряк, ты слишком долго плавал! Попробуй еще раз!». Не самый элегантный подход, но простой, как грабли.
А теперь нам нужно думать. Что делать, если запрашиваемый сервис сейчас недоступен, например? Забить на эту celery-таску? Или закинуть ее еще раз в очередь, вдруг во второй раз она выполнится успешно? Или в третий?
Тоже вполне себе рабочий подход.
Но почему вообще первый микросервис должен заботиться о всех этих вещах? Почему он вообще должен знать о других сервисах, если для работы с пользователем ему другие сервисы не нужны-то напрямую?

13)
И тут возникает мысль.
А вдруг нам здесь может как-то помочь Kafka?

14)
Но давайте сначала чуть-чуть посмотрим, что такое кафка.


15)
Кафка изначально разрабатывалась как очередь сообщений внутри линкедина, заблокированного на территории Российской Федерации.
Но переросла уже в что-то, что назвают распределенной системой потоковой передачи данных, обладащей высокой пропускной способоностью, позволяющей масштабируемо собирать данные.

16)
Для чего кафку используют?
Для сбора и передачи сообщений. В том числе каких-то метрик, каких-то действий пользователя на сайте.
Можно использовать для сбора логов приложений. 
Да много для чего можно использовать.
В том числе и для построения очередей.

В принципе, что-то из этого можно делать и с использованием других технологий. С помощью того же редиса, например, про который будет сегодня доклад чуть попозже.

17)
Но кафка нас зацепила вот такими цифрами.
Конечно, это синтетические бенчмарки, но цифры-то впечатляют!

18)
А есть ли вообще хорошие альтернативы Кафке?
Зачастую приводят вот такие интрументы.

Рэбит и Актив MQ не могут похвастаться такими цифрами в плане производителности, да и с масштабированием у них чуть похуже.

А вот эта тройка, NATS, Pulsar, NSQ, вполне себе хвалится цифрами в бенчмарках. Где-то даже эти цифры поинтереснее.
Но нужно же еще смотреть и на популярность технологии. На поддержку со стороны сообщества и различных вендоров. Сейчас Кафка выигрывает в этом плане.

Ну и Kinesis. Если вы хотите привязать себя намертво к амазону, то почему бы и нет. Тем более у кинезиса есть много интересных штук...
Но если вы хотите чувствовать себя посвободнее, то амазон с недавних пор предоставляет Кафку как сервис. Дороговато чуть-чуть, но убирает головную боль по администрированию кластера в какой-то степени.

19)
Посмотрим, как работать с кафкой, на хайлевеле, так сказать.
У нас есть кластер кафки и внутри этого кластера есть топики, своего рода именованные очереди.
И есть продьюсеры с консумерами.
Продьюсеры, производители, производят запись каких-то сообщений в выбранный топик.
А консумеры, потребители, забирают записанные данные из тех топиков, на которые они подписаны.

20)
Топик внутри себя может содержать несколько партиций. Разбиение топика на партиции позволяет сильно повышать производительность записи. Т.к. партиции одного топика могут храниться как на разных дисках одной машины, так и вовсе на разных машинах.
Размер топика, размер партиций, теоретически ничем не ограничены, разве что размером диска. И временем жизни сообщения, которое вы можете также изменить.

21)
И так у нас есть топик, разбитый на четыре раздела.
И есть две группы потребителей. Каждому консумеру в группе какфка назначает набор партиций, который он будет обрабатывать, от одного до нескольких. Зависит от количества партиций и от количества консумеров в группе. Однако, есть принципиальное ограничение, одна партиция не может обрабатываться сразу двумя консумерами из ОДНОЙ группы. Как видите, пятый консумер первой группы простаивает.

Но группы потребителей работают независимо. Сообщения из топика после обработки не удаляются, поэтому вторая группа может обработать те же сообщения, но уже со своей логикой обработки.

22)
Для понимания того, какие сообщения какой группе консумеров отдавать используется концепция офсетов.
Давайте посмотрим на примере топика, у которого только одна партиция.
Первая группа обработала 5 сообщений и работает над шестым. Сообщения из топика не удаляются после обработки.
Вторая группа работает помедленнее, обработала два сообщения, трудится над третьим.

23)
Продьюсеры накидали в ощередь пару новых сообщений.
Группы  консумеров продолжают трудиться со своей скоростью, обрабатывая сообщения и сообщая кафке, что сообщения ими обработаны. Т.е. они "коммитают" оффсет по мере обработки сообщений.

24)
пришла еще одна группа потребителей и начала обрабатывать топик с самого начала
А продьюсеры подкидывают все работки.
Все сообщения идут строго одно-за другим. Порядок гарантирован: все сообщения будут обработаны одно за другим консумерами.

25)
А вот пришла четвертая группа и решила "да в гробу я видала эти старые сообщения, начну с актуальных". И так тоже можно.

26)
Есть различные способы управления оффсетом. Консьюмер может начать как с начала очереди, так и с конца. Или "отмотать" оффсет на произвольную дату, или на несколько позиций вперед\назад.
Очень гибко все

27)
С одной партицией было попроще, а если их три?
Тогда сообщения, приходящие от продьюсеров, будут по какой-то логике распределяться по трем партициям.
У нас уже не будет четкой гарантии того, что все сообщения в рамках топика идут один за одним, ровно в том порядке, как они пришли в кафку. И хоть эта гарантия все еще есть на уровне партиции, мы можем попасть на проблему с затыком консумеров.
Поэтому, или одна партиция на топик и строгая гарантия последовательности событий, или же скорость\производительность, но последовательность теряется.

Интересно, все же, что, кроме, скорости, дают нам партиции?

28)
Давайте посмотрим еще раз.
И так, есть кластер кафки

29)
Внутри кластера есть три брокера.
Это достаточно стандартная, минимальная, простейшая, конфигурация.
Три брокера в кластере. У каждого топика фактор репликации тоже выставлен в тройку. 
Таким образом каждый топик со всеми его партициями скопирован на каждый брокер.
Есть разные подходы для реплицирования: кто-то использует кворум, кто-то концепцию лидеров. Какфка использует лидеров.
Осталось понять, кто лидер.

30)
В кафке для каждой реплицированной партиции выбирается свой лидер. Лидеры распределены по разным брокерам, а не сосредоточены на одном.

31)
Когда продьюсер делает запись в топик, он точно знает, в какую партицию он записывает. И, соответственно, он точно знает, на каком брокере расположен лидер этой партиции.
После того, как сообщение записал лидер, оно реплицируется на всех остальные реплики.
Причем продьюсер может работать по двум разным стратегиям:
- по синхронной: он будет ждать, пока закончится реплицирования
- по асинхронной: он подождет только лидера
первая стратегия надежнее, вторая - быстрее. выбирать -- вам.

Если брокер номер 1 упадет, то кафка найдет, назначит лидеров для нулевой и второй партиции на других брокерах.
Если вы использовали асинхронную стратегию, то часть данных может быть потеряна в этом случае.

Очень за многое отвечает продьюсер. Не только за стратегию записи.
Но в том числе и за решение того, в какую конкретную партицию будет помещено сообщение. Он это может решать с помощью рандома, или же основываясь на содержимом сообщения.

32)
В простейшем случае содержимое сообщения представляет из себя вот это.
Ключ, значение. И то, и другое - набор байтов.
Хоть mp3'шки туда кидайте!.
Но зачастую это все-таки какие-то структуры данных, которые надо как-то сериализовать.

33)
Можно использовать любые сериализаторы, конечно.
Можно хоть Pickle!
Но лучше какие-то популярные, кросс-языковые.
В мире кафки хорошо Avro прижился. Он бинарный. Со схемой. И валидацию поддерживает, и миграцию.

34)
однако, есть недостаток. с каждым сообщением нужно передавать схему, чтобы можно было десериализовать. это невыгодно, даже по сравнению с json
но есть выход: держать схемы отдельно, в доступном для десиарилизатора месте.

35)
Такое место - реестр схем.
Самое популярное решение для кафки - от конфлуента.

36)
Но давайте обратно к нашим микросервисам

37)
Мы остановились на варианте с celery и хотим что-то изменить

38)
Внедряем кафку.
Первый сервис пишет в кафку.
А дальше мы уже в других сервисах, местами, отказывается от реста и назначаем их ответственными за реагирование на происходящие изменения в первом сервисе.
У второго и третьего сервиса появились маленькие подсервисы - кафка консумеры.
Вроде бы неплохо. 
Но можно лучше.

39)
Как видно, первый сервис при своей работе что-то изменяет в своей базе данных. А потом сообщает о этих изменениях в кафку.
Двойная работа.
Может, ну ее, эту кафку? 
Зачем одни и те же данные писать два раза в два места, и поддерживать эту логику в коде сервиса?
Было бы хорошо, если бы данные сами в кафку ходили!

40)
И так тоже можно!
Дебезиум нам это даст

41)
Дебезиум реализует по своей сути концепт кафка-коннектора.
Вот схема с их сайта.
Элементов много.

42)
Нас интересуют только вот эти
Дебезиум читает лог постгреса  и транслирует изменения в кафку. 

43)
и теперь вот эта прошлая схема 

44)
превращается вот в эту.
кода в сервисе стало меньше
дебезиум делает работу за нас.
в принципе можно было бы и со вторым сервисом и его базой что-то намутить, но пока оставим как есть.

45)
Итого мы пришли к вот такому решению.
Схема в виде палочек не очень понятная, да?

46)
Давайте что-то более привычное нарисуем.
Вот на этой схеме можно заметить, что с помощью дебезиума и кафки мы полностью отвязали наше впереди-стоящее джанго приложение от остальных микросервисов.

Но а что по поводу большого потока данных из внешних источников

47)

Еще пара микросервисов решат эту задачу.
Забираем данные, помещаем в кафку.
Достаем из кафки, анализируем, преобразуем, кладем в базу данных основного сервиса.

Все бы хорошо, вот только слищком много Java-технологий теперь у нас в проекте. Kafka,... Debezium...

48)
А что про питон?

49)
В питоне есть четыре популярных библиотеки для работы с кафкой.
Три основных и одна для acyncio.
Но у нас джанго.

50)
Давайте посмотрим, что выбрать из трех основных.
Можно выбрать по звездам на гитхабе, все так делают!
Но еще можно посмотреть на статистику по контрибьютерам, посотреть что там как с релизами и активностью разработки.
У pykafka с этим проблемы в последнее время...

51)
А еще давайте взглянем на бенчмарки
По цифрам всех бьет  библиотека от confluent.
kafka-python совсем отствает.
а pykafka, как мы знаем из предыдущего слайда, испытывает некоторые проблемы с релизами и активностью разработки

52)
Наконце-то мы дошли до кода!
Это пример простейшего продьюсера, использующего confluent-kafka-python для работы с кафкой.

Прошу прощения за избыточную компактность кода. Хотел все в один слайд поместить.

53)
А это - Консьюмер.

54)
Надо бы сделать какие-то выводы.
Как вы заметили. Я много рассказывал про кафку и вещи вокруг нее, но мало про питон. Когда вы погружаетесь в микросервисный адочек, то питон отходит слегка на второй план.
Хорошо это или плохо -- решать вам.

55)
Спасибо за внимание

56)
Буду рад вашим вопросам.
