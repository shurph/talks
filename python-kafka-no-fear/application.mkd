# Расскажите пару слов о себе *
## Компания, должность, заслуги, ссылки на блог или профайл.
bitnet, Lead Software Engineer
увлекаюсь публичным говорением в последнее время, список выступлений здесь (со ссылками на видео, где доступно): https://shurph.github.io/talks/

Профили:
Twitter: http://twitter.com/shurph 
GitHub: http://github.com/shurph
LinkedIn: https://www.linkedin.com/in/nikolay-saskovets/

Текст "О спикере" { черновик :-) }:
Николаю доводилось начинать, проводить, забрасывать и завершать процессы перевода монолитных приложений к микросервисной архитектуре как python-only приложений, так и довольно гетерогенных в плане языков программирования, и технологического стека в общем, проектов. В процессе этих увлекательных приключений так или иначе приходилось сталкиваться с различными технологиями, подходами, решениями. Какие-то из этих решений оказали неизгладимое впечатление на него самого и на команды, в которых он работал.

Теперь Николай стремится делиться своей радостью и болью от интересных технологических находок с сообществом.


# Тема доклада

Kafka — это не так уж и страшно: мы справляемся с экзистенциальным беспокойством, и вы справитесь!


# Описание доклада *
{ 30–40-минутный доклад }

Планирую рассказать о том, как с нуля до продакшена внедрить кафку, показывая решения на примере нашего опыта в текущем проекте.
По большей части, будут рассматриваться существующие сейчас "best practices" по работе с Kafka, но, возможно, где-то будут слегка упрощенные варианты.


"Анонс" для публики:

Когда ваше приложение беззаботно оперирует сотней-другой событий в секунду, основывая свои действия на ручейке данных из внешнего мира, то всё вокруг кажется красочным и прекрасным. Но окружающий мир непредсказуем, и внезапно могут возникнуть жесткие требования к надежности и безопасности некоторых частей приложения, а другим частям бизнес может пообещать вместо ручейка данных — настоящий водопад!

Все эти вызовы окружающей среды могут решаться по-разному, но в нашем случае сквозь все решения проходит Kafka.

Так, чтобы справиться с водопадом данных от внешних источников, Kafka подходит как ничто лучше, обещая обработать до 2 миллионов записей в секунду.

А ещё мы постарались безболезненно внедрить Kafka в проект на Django, в качестве шины обмена данными, чтобы как-то справиться с намечающимся водоворотом микросервисного ада.

В конце концов, когда у вас в руках Кафка, то всё вокруг кажется потоком.

# На кого рассчитан доклад? *

Доклад рассчитан на разработчиков и тимлидов, которые подумывают о том, чтобы попробовать Kafka в рамках своих проектов.

# Какие ценные мысли люди смогут вынести из моего доклада? *

Опираясь на пример нашего опыта и мои общие теоретические выкладки, смогут чуть ближе подойти к решению, подходит ли это Kafka для их задач и стоит ли пристальнее взглянуть на Kafka.

Должно возникнуть понимание того, что Kafka — не такой уж и страшный зверь :-)
